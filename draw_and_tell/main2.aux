\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{deepnet:nips12,Decaf:icml2014,vgg16}
\citation{rcnn,Long_2015_CVPR,rcnn_crf}
\citation{open:surface}
\citation{whatpoint,coco:eccv}
\citation{scalable:annotation,coco:eccv}
\citation{rcnn,rcnn_crf,crfasrnn}
\citation{weak:seg:xu,BoxSup,ConsCNN}
\citation{whatpoint}
\citation{markov:topic,cnn:em}
\@writefile{toc}{\contentsline {title}{Draw\&Tell: Efficient Annotation for Semantic Image Segmentation by Drawing and Speaking}{1}{chapter.1}}
\@writefile{toc}{\authcount {1}}
\@writefile{toc}{\contentsline {author}{Anonymous ECCV submission}{1}{chapter.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1.1}}
\@writefile{brf}{\backcite{deepnet:nips12, Decaf:icml2014, vgg16}{{1}{1}{section.1.1}}}
\@writefile{brf}{\backcite{rcnn, Long_2015_CVPR, rcnn_crf}{{1}{1}{section.1.1}}}
\citation{open:surface}
\citation{coco:eccv}
\citation{Long_2015_CVPR}
\citation{Long_2015_CVPR}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A comparison of our annotation (e) to other forms of annotations for semantic segmentation, ranging from (a) full segmentation masks, to (b) bounding boxes, to (c) single points, and to (d) image-level keywords. The devices to obtain these annotations are shown as well: others only use the mouse (+keyboard), while ours also uses voice input through a microphone. }}{2}{figure.1.1}}
\newlabel{fig:1}{{1}{2}{A comparison of our annotation (e) to other forms of annotations for semantic segmentation, ranging from (a) full segmentation masks, to (b) bounding boxes, to (c) single points, and to (d) image-level keywords. The devices to obtain these annotations are shown as well: others only use the mouse (+keyboard), while ours also uses voice input through a microphone}{figure.1.1}{}}
\@writefile{brf}{\backcite{open:surface}{{2}{1}{figure.1.1}}}
\@writefile{brf}{\backcite{whatpoint, coco:eccv}{{2}{1}{figure.1.1}}}
\@writefile{brf}{\backcite{scalable:annotation, coco:eccv}{{2}{1}{figure.1.1}}}
\@writefile{brf}{\backcite{rcnn, rcnn_crf, crfasrnn}{{2}{1}{figure.1.1}}}
\@writefile{brf}{\backcite{weak:seg:xu, BoxSup, ConsCNN}{{2}{1}{figure.1.1}}}
\@writefile{brf}{\backcite{whatpoint}{{2}{1}{figure.1.1}}}
\@writefile{brf}{\backcite{markov:topic, cnn:em}{{2}{1}{figure.1.1}}}
\@writefile{brf}{\backcite{open:surface}{{2}{1}{figure.1.1}}}
\@writefile{brf}{\backcite{coco:eccv}{{2}{1}{figure.1.1}}}
\citation{Long_2015_CVPR}
\citation{Long_2015_CVPR}
\citation{texton:boost,fully-crf}
\citation{rcnn}
\citation{Long_2015_CVPR,rcnn_crf,crfasrnn}
\citation{cnn:mil}
\citation{Long_2015_CVPR}
\citation{cnn:em,BoxSup,ConsCNN}
\citation{whatpoint}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The framework of the standard fully convolutional network (FCN)\nobreakspace  {}\cite  {Long_2015_CVPR} and our heatmap-based FCN.}}{3}{figure.1.2}}
\@writefile{brf}{\backcite{Long_2015_CVPR}{{3}{2}{figure.1.2}}}
\newlabel{fig:2}{{2}{3}{The framework of the standard fully convolutional network (FCN)~\cite {Long_2015_CVPR} and our heatmap-based FCN}{figure.1.2}{}}
\@writefile{brf}{\backcite{Long_2015_CVPR}{{3}{1}{figure.1.1}}}
\@writefile{brf}{\backcite{Long_2015_CVPR}{{3}{1}{figure.1.1}}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{3}{section.1.2}}
\newlabel{sec:related}{{2}{3}{Related Work}{section.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Semantic Image Segmentation}{3}{subsection.1.2.1}}
\@writefile{brf}{\backcite{texton:boost, fully-crf}{{3}{2.1}{subsection.1.2.1}}}
\@writefile{brf}{\backcite{rcnn}{{3}{2.1}{subsection.1.2.1}}}
\citation{camvid:data}
\citation{NYU}
\citation{pascal:2011}
\citation{coco:eccv}
\citation{pascal:context}
\citation{open:surface,label:me}
\citation{scalable:annotation,coco:eccv}
\citation{AFrameSel,expected:loss}
\citation{detect:eyetr}
\citation{show:tell:caption,youtube2text,fgm:coling14,deep:alignment:vl,babytalk}
\citation{pixel:tone}
\citation{image:spirit}
\citation{show:tell,speech:anno:img,speech:retri:img,video:anno:knowledgebase}
\citation{smile}
\citation{geodesic:star}
\citation{end-to-end:speech}
\citation{end-to-end:speech}
\@writefile{brf}{\backcite{Long_2015_CVPR, rcnn_crf, crfasrnn}{{4}{2.1}{subsection.1.2.1}}}
\@writefile{brf}{\backcite{cnn:mil}{{4}{2.1}{subsection.1.2.1}}}
\@writefile{brf}{\backcite{Long_2015_CVPR}{{4}{2.1}{subsection.1.2.1}}}
\@writefile{brf}{\backcite{cnn:em, BoxSup, ConsCNN}{{4}{2.1}{subsection.1.2.1}}}
\@writefile{brf}{\backcite{whatpoint}{{4}{2.1}{subsection.1.2.1}}}
\@writefile{brf}{\backcite{camvid:data}{{4}{2.1}{subsection.1.2.1}}}
\@writefile{brf}{\backcite{NYU}{{4}{2.1}{subsection.1.2.1}}}
\@writefile{brf}{\backcite{pascal:2011}{{4}{2.1}{subsection.1.2.1}}}
\@writefile{brf}{\backcite{coco:eccv}{{4}{2.1}{subsection.1.2.1}}}
\@writefile{brf}{\backcite{pascal:context}{{4}{2.1}{subsection.1.2.1}}}
\@writefile{brf}{\backcite{open:surface, label:me}{{4}{2.1}{subsection.1.2.1}}}
\@writefile{brf}{\backcite{scalable:annotation, coco:eccv}{{4}{2.1}{subsection.1.2.1}}}
\@writefile{brf}{\backcite{AFrameSel, expected:loss}{{4}{2.1}{subsection.1.2.1}}}
\@writefile{brf}{\backcite{detect:eyetr}{{4}{2.1}{subsection.1.2.1}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Integration of Vision and Language (Speech)}{4}{subsection.1.2.2}}
\@writefile{brf}{\backcite{ show:tell:caption, youtube2text, fgm:coling14, deep:alignment:vl, babytalk}{{4}{2.2}{subsection.1.2.2}}}
\@writefile{brf}{\backcite{pixel:tone}{{4}{2.2}{subsection.1.2.2}}}
\@writefile{brf}{\backcite{image:spirit}{{4}{2.2}{subsection.1.2.2}}}
\@writefile{brf}{\backcite{show:tell, speech:anno:img, speech:retri:img, video:anno:knowledgebase}{{4}{2.2}{subsection.1.2.2}}}
\@writefile{brf}{\backcite{smile}{{4}{2.2}{subsection.1.2.2}}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Speech-based Annotation}{4}{section.1.3}}
\newlabel{sec:annotation}{{3}{4}{Speech-based Annotation}{section.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}The Draw \& Tell Annotation Tool}{4}{subsection.1.3.1}}
\citation{SR:review}
\citation{lexfree2015}
\citation{edge:box}
\@writefile{brf}{\backcite{geodesic:star}{{5}{3.1}{subsection.1.3.1}}}
\@writefile{brf}{\backcite{end-to-end:speech}{{5}{3.1}{subsection.1.3.1}}}
\@writefile{brf}{\backcite{end-to-end:speech}{{5}{3.1}{subsection.1.3.1}}}
\@writefile{brf}{\backcite{SR:review}{{5}{3.1}{subsection.1.3.1}}}
\@writefile{brf}{\backcite{lexfree2015}{{5}{3.1}{subsection.1.3.1}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Integration with Webly Supervised Object Recognition}{5}{subsection.1.3.2}}
\newlabel{sec:web}{{3.2}{5}{Integration with Webly Supervised Object Recognition}{subsection.1.3.2}{}}
\@writefile{brf}{\backcite{edge:box}{{5}{3.2}{subsection.1.3.2}}}
\citation{webly:cnn}
\citation{rcnn}
\citation{webly:cnn}
\citation{vgg16}
\citation{imagenet}
\citation{sphinx}
\citation{sphinx:webtrain}
\citation{pascal:2011}
\citation{coco:eccv}
\citation{end-to-end:speech,lexfree2015}
\citation{coco:eccv}
\@writefile{brf}{\backcite{webly:cnn}{{6}{3.2}{subsection.1.3.2}}}
\@writefile{brf}{\backcite{rcnn}{{6}{3.2}{subsection.1.3.2}}}
\@writefile{brf}{\backcite{webly:cnn}{{6}{3.2}{subsection.1.3.2}}}
\@writefile{brf}{\backcite{vgg16}{{6}{3.2}{subsection.1.3.2}}}
\@writefile{brf}{\backcite{imagenet}{{6}{3.2}{subsection.1.3.2}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Annotation Results}{6}{subsection.1.3.3}}
\@writefile{brf}{\backcite{sphinx}{{6}{3.3}{subsection.1.3.3}}}
\@writefile{brf}{\backcite{pascal:2011}{{6}{3.3}{subsection.1.3.3}}}
\@writefile{brf}{\backcite{coco:eccv}{{6}{3.3}{subsection.1.3.3}}}
\@writefile{brf}{\backcite{sphinx:webtrain}{{6}{1}{Hfootnote.1}}}
\citation{pascal:2011}
\citation{semantic:contour}
\citation{whatpoint}
\citation{whatpoint}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Recognition accuracy (\%) of object names, where speech means our method without the help of the object recognition, web denotes only using the object recognition, and combined stands for our final method.}}{7}{table.1.1}}
\newlabel{table:class:eval}{{1}{7}{Recognition accuracy (\%) of object names, where speech means our method without the help of the object recognition, web denotes only using the object recognition, and combined stands for our final method}{table.1.1}{}}
\@writefile{brf}{\backcite{end-to-end:speech,lexfree2015}{{7}{3.3}{subsection.1.3.3}}}
\@writefile{brf}{\backcite{coco:eccv}{{7}{3.3}{subsection.1.3.3}}}
\@writefile{brf}{\backcite{pascal:2011}{{7}{3.3}{table.1.1}}}
\@writefile{brf}{\backcite{semantic:contour}{{7}{3.3}{table.1.1}}}
\@writefile{brf}{\backcite{whatpoint}{{7}{3.3}{table.1.2}}}
\citation{best:two:world,annotation:strength}
\citation{open:surface}
\citation{rcnn,Long_2015_CVPR,crfasrnn}
\citation{Long_2015_CVPR}
\citation{geodesic:star}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Errors (\%) of the annotation: false positives and false negatives at object-level, and the percentages of pixels drawing to the background and objects of other classes for the scribbles which are `correct' at object-level. }}{8}{table.1.2}}
\newlabel{table:anno}{{2}{8}{Errors (\%) of the annotation: false positives and false negatives at object-level, and the percentages of pixels drawing to the background and objects of other classes for the scribbles which are `correct' at object-level}{table.1.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces The annotation speed (seconds per image) of all methods, measured on PASCAL VOC.}}{8}{table.1.3}}
\newlabel{table:speed}{{3}{8}{The annotation speed (seconds per image) of all methods, measured on PASCAL VOC}{table.1.3}{}}
\@writefile{brf}{\backcite{whatpoint}{{8}{3.3}{table.1.2}}}
\@writefile{brf}{\backcite{best:two:world, annotation:strength}{{8}{3.3}{table.1.2}}}
\@writefile{brf}{\backcite{open:surface}{{8}{3.3}{table.1.2}}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Semantic Image Segmentation}{8}{section.1.4}}
\newlabel{sec:method}{{4}{8}{Semantic Image Segmentation}{section.1.4}{}}
\@writefile{brf}{\backcite{rcnn, Long_2015_CVPR, crfasrnn}{{8}{4}{section.1.4}}}
\@writefile{brf}{\backcite{Long_2015_CVPR}{{8}{4}{section.1.4}}}
\citation{geodesic:star}
\citation{edge:srf}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces An example of scribble augmentation and heatmap generation: (a) annotated scribbles; (b) augmented scribbles for the background; (c) generated semantic heatmaps for the two objects.}}{9}{figure.1.3}}
\newlabel{fig:3}{{3}{9}{An example of scribble augmentation and heatmap generation: (a) annotated scribbles; (b) augmented scribbles for the background; (c) generated semantic heatmaps for the two objects}{figure.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Scribbles to Heatmaps}{9}{subsection.1.4.1}}
\newlabel{sec:scribble}{{4.1}{9}{Scribbles to Heatmaps}{subsection.1.4.1}{}}
\@writefile{brf}{\backcite{geodesic:star}{{9}{4.1}{subsection.1.4.1}}}
\newlabel{eq:heatmap}{{2}{9}{Scribbles to Heatmaps}{equation.1.4.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{Scribble Augmentation}{9}{section*.2}}
\@writefile{brf}{\backcite{geodesic:star}{{9}{4.1}{section*.2}}}
\newlabel{eq:gdist}{{3}{9}{Scribble Augmentation}{equation.1.4.3}{}}
\citation{edge:box}
\citation{Long_2015_CVPR}
\citation{Long_2015_CVPR}
\citation{cnn:em}
\@writefile{brf}{\backcite{edge:srf}{{10}{4.1}{equation.1.4.3}}}
\newlabel{eq:gdist2}{{4}{10}{Scribble Augmentation}{equation.1.4.4}{}}
\newlabel{eq:gdist:set}{{5}{10}{Scribble Augmentation}{equation.1.4.5}{}}
\newlabel{eq:sampling}{{6}{10}{Scribble Augmentation}{equation.1.4.6}{}}
\@writefile{brf}{\backcite{edge:box}{{10}{4.1}{equation.1.4.6}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Heatmap-based FCN}{10}{subsection.1.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  Probability map for sampling the next new scribble (c.f.\spacefactor \@m {}\xspace  Eq.\ref  {eq:sampling}).}}{10}{figure.1.4}}
\newlabel{fig:4}{{4}{10}{Probability map for sampling the next new scribble (\cf Eq.\ref {eq:sampling})}{figure.1.4}{}}
\@writefile{brf}{\backcite{Long_2015_CVPR}{{10}{4.2}{subsection.1.4.2}}}
\@writefile{brf}{\backcite{Long_2015_CVPR}{{10}{4.2}{subsection.1.4.2}}}
\@writefile{brf}{\backcite{cnn:em}{{10}{4.2}{subsection.1.4.2}}}
\newlabel{eq:fcn}{{7}{10}{Heatmap-based FCN}{equation.1.4.7}{}}
\newlabel{eq:fcnloss}{{8}{10}{Heatmap-based FCN}{equation.1.4.8}{}}
\citation{pascal:2011}
\citation{Long_2015_CVPR,ConsCNN,cnn:em,whatpoint}
\citation{semantic:contour}
\citation{Long_2015_CVPR}
\citation{vgg16}
\citation{imageNet:challenge}
\citation{Caffe}
\citation{ConsCNN}
\citation{whatpoint}
\citation{cnn:em}
\citation{Long_2015_CVPR}
\citation{cnn:mil}
\citation{img:pix:cnn}
\citation{whatpoint}
\citation{cnn:em}
\citation{BoxSup}
\citation{SDS}
\citation{Long_2015_CVPR}
\citation{zoomout:fet}
\citation{rcnn_crf}
\@writefile{brf}{\backcite{ConsCNN}{{11}{5.1}{subsection.1.5.1}}}
\@writefile{brf}{\backcite{whatpoint}{{11}{5.1}{subsection.1.5.1}}}
\@writefile{brf}{\backcite{cnn:em}{{11}{5.1}{subsection.1.5.1}}}
\@writefile{brf}{\backcite{Long_2015_CVPR}{{11}{5.1}{subsection.1.5.1}}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces The results of different methods with varying levels of supervision on the validation set of PASCAL VOC 2012.}}{11}{table.1.4}}
\newlabel{table:val}{{4}{11}{The results of different methods with varying levels of supervision on the validation set of PASCAL VOC 2012}{table.1.4}{}}
\newlabel{eq:ourloss}{{9}{11}{Heatmap-based FCN}{equation.1.4.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Experiments}{11}{section.1.5}}
\newlabel{sec:experiments}{{5}{11}{Experiments}{section.1.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Experimental Settings}{11}{subsection.1.5.1}}
\@writefile{brf}{\backcite{pascal:2011}{{11}{5.1}{subsection.1.5.1}}}
\@writefile{brf}{\backcite{Long_2015_CVPR, ConsCNN, cnn:em, whatpoint}{{11}{5.1}{subsection.1.5.1}}}
\@writefile{brf}{\backcite{semantic:contour}{{11}{5.1}{subsection.1.5.1}}}
\@writefile{brf}{\backcite{Long_2015_CVPR}{{11}{5.1}{subsection.1.5.1}}}
\@writefile{brf}{\backcite{vgg16}{{11}{5.1}{subsection.1.5.1}}}
\@writefile{brf}{\backcite{imageNet:challenge}{{11}{5.1}{subsection.1.5.1}}}
\@writefile{brf}{\backcite{Caffe}{{11}{5.1}{subsection.1.5.1}}}
\citation{rcnn_crf,ConsCNN}
\citation{fully-crf}
\citation{Long_2015_CVPR}
\citation{cnn:em}
\citation{whatpoint,ConsCNN}
\@writefile{brf}{\backcite{cnn:mil}{{12}{5.1}{table.1.4}}}
\@writefile{brf}{\backcite{img:pix:cnn}{{12}{5.1}{table.1.4}}}
\@writefile{brf}{\backcite{whatpoint}{{12}{5.1}{table.1.4}}}
\@writefile{brf}{\backcite{cnn:em}{{12}{5.1}{table.1.4}}}
\@writefile{brf}{\backcite{BoxSup}{{12}{5.1}{table.1.4}}}
\@writefile{brf}{\backcite{SDS}{{12}{5.1}{table.1.4}}}
\@writefile{brf}{\backcite{Long_2015_CVPR}{{12}{5.1}{table.1.4}}}
\@writefile{brf}{\backcite{zoomout:fet}{{12}{5.1}{table.1.4}}}
\@writefile{brf}{\backcite{rcnn_crf}{{12}{5.1}{table.1.4}}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Comparison to other methods with different levels of supervision on PASCAL VOC 2012 test.}}{12}{table.1.5}}
\newlabel{table:voc12:test}{{5}{12}{Comparison to other methods with different levels of supervision on PASCAL VOC 2012 test}{table.1.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Results}{12}{subsection.1.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The performance of HFCN-3 as a function of $T$.}}{12}{figure.1.5}}
\newlabel{fig:scribble:aug}{{5}{12}{The performance of HFCN-3 as a function of $T$}{figure.1.5}{}}
\@writefile{brf}{\backcite{rcnn_crf,ConsCNN}{{12}{5.2}{figure.1.5}}}
\@writefile{brf}{\backcite{fully-crf}{{12}{5.2}{figure.1.5}}}
\@writefile{brf}{\backcite{Long_2015_CVPR}{{12}{5.2}{figure.1.5}}}
\@writefile{brf}{\backcite{cnn:em}{{12}{5.2}{figure.1.5}}}
\@writefile{brf}{\backcite{whatpoint, ConsCNN}{{12}{5.2}{figure.1.5}}}
\citation{img:pix:cnn}
\citation{BoxSup}
\citation{MCG}
\citation{cnn:em,BoxSup}
\citation{rcnn_crf,cnn:em,ConsCNN}
\citation{fully-crf}
\citation{BoxSup}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Examples of the segmentation results on the validation set of PASCAL VOC 2012.}}{13}{figure.1.6}}
\newlabel{fig:5}{{6}{13}{Examples of the segmentation results on the validation set of PASCAL VOC 2012}{figure.1.6}{}}
\@writefile{brf}{\backcite{img:pix:cnn}{{13}{5.2}{figure.1.5}}}
\@writefile{brf}{\backcite{BoxSup}{{13}{5.2}{figure.1.5}}}
\@writefile{brf}{\backcite{MCG}{{13}{5.2}{figure.1.5}}}
\@writefile{brf}{\backcite{cnn:em, BoxSup}{{13}{5.2}{figure.1.5}}}
\@writefile{brf}{\backcite{rcnn_crf, cnn:em, ConsCNN}{{13}{5.2}{figure.1.5}}}
\@writefile{brf}{\backcite{fully-crf}{{13}{5.2}{figure.1.5}}}
\bibstyle{splncs}
\bibdata{egbib}
\@writefile{brf}{\backcite{BoxSup}{{14}{5.2}{figure.1.6}}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Annotation vs. segmentation performance (mIoU) of all the methods considered. Evaluated on PASCAL VOC 2012 test.}}{14}{figure.1.7}}
\newlabel{fig:6}{{7}{14}{Annotation vs. segmentation performance (mIoU) of all the methods considered. Evaluated on PASCAL VOC 2012 test}{figure.1.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{14}{section.1.6}}
\newlabel{sec:con}{{6}{14}{Conclusion}{section.1.6}{}}
