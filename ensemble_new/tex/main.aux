\relax 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\emailauthor{dai@vision.ee.ethz.ch}{Dengxin Dai\corref {cor1}}
\urlauthor{www.vision.ee.ethz.ch/\hashchar daid/}{Dengxin Dai\corref {cor1}}
\emailauthor{vangool@vision.ee.ethz.ch}{Luc Van Gool}
\Newlabel{cor1}{1}
\citation{lazebnik:cvpr06,Indoor,siftllc:cvpr10,Sun_2010,Yang_2014_CVPR,nips12:cnn}
\citation{game:purpose}
\citation{labelme}
\citation{stl-10,cnnfet14,feature:context,feature:LSTM}
\citation{Fergus09,Guillaumin:cvpr:10,dai:iccv13b}
\citation{JainK:cvpr09,cvpr09:multi:al}
\citation{Transfer:CVPR:08,tl:survey}
\citation{cvpr12:weak:video,metric:imitation}
\citation{self-taught:icml07}
\citation{Sivic05b,dai}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\newlabel{sec:intro}{{1}{1}{Introduction\relax }{section.1}{}}
\citation{SemiSVM,Joachims:1999,SemiBoost,SemiForest}
\citation{gist,Ojala02,Bosch:iccv07,siftllc:cvpr10}
\citation{caffe14,rich:feature:cvpr14,deep:bmvc14}
\citation{stl-10,cnnfet14,feature:context,feature:LSTM,feature:video}
\citation{Zhou:nips:04,deep:semi:embedding,Fergus09,SemiForest,Zhu:ISL:2009,nips14:ssl}
\citation{Grauman06,Frey_AffinityPropagation,dai}
\citation{stl-10,cnnfet14,feature:LSTM,feature:video}
\citation{Rosch:1978}
\citation{Transfer:CVPR:08}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Motivations}{2}{subsection.1.1}}
\citation{Rosch:1978}
\citation{EnClasReview}
\citation{Rosch:1978}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The pipeline of Ensemble Projection (EP). EP consists of unsupervised feature learning (left panel) and plain classification or clustering (right panel). For feature learning, EP samples an ensemble of $T$ diverse prototype sets from all known images and learns discriminative classifiers on them for the projection functions. Images are then projected using these functions to obtain their new representation. These features are fed into standard classifiers and clustering methods for image classification and clustering respectively.}}{3}{figure.1}}
\newlabel{fig:pipeline}{{1}{3}{The pipeline of Ensemble Projection (EP). EP consists of unsupervised feature learning (left panel) and plain classification or clustering (right panel). For feature learning, EP samples an ensemble of $T$ diverse prototype sets from all known images and learns discriminative classifiers on them for the projection functions. Images are then projected using these functions to obtain their new representation. These features are fed into standard classifiers and clustering methods for image classification and clustering respectively}{figure.1}{}}
\citation{dai:eccv12b,dai:iccv13b}
\citation{Ojala02}
\citation{gist}
\citation{Bosch:iccv07}
\citation{nips12:cnn,caffe14,rich:feature:cvpr14,deep:bmvc14}
\citation{dai:iccv13b}
\citation{random:hashing}
\citation{ObjectAttribute:cvpr09}
\citation{eccv10:classemes}
\citation{li:objectbank}
\citation{augmented_attribute:eccv12,design_attribute:cvpr13}
\citation{nips12:cnn,caffe14,rich:feature:cvpr14,deep:bmvc14}
\citation{midlevel:transfer,cnn:transferable}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Contributions}{4}{subsection.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{4}{section.2}}
\newlabel{sec:related}{{2}{4}{Related Work\relax }{section.2}{}}
\citation{stl-10}
\citation{cnnfet14}
\citation{mid-level:patches}
\citation{feature:context}
\citation{feature:video}
\citation{learning:by:moving}
\citation{book06:ssl,Zhu:ISL:2009}
\citation{co-training:98}
\citation{Guillaumin:cvpr:10}
\citation{Semi:eccv12}
\citation{Guillaumin:cvpr:10}
\citation{Semi:eccv12}
\citation{Zhu:Harmonic:03}
\citation{Zhou:nips:04}
\citation{Belkin:semiframe:2006}
\citation{Fergus09}
\citation{Joachims:1999}
\citation{SemiSVM}
\citation{SemiForest}
\citation{Zhu:ISL:2009}
\citation{SemiBoost}
\citation{SemiForest}
\citation{ensemble:iccv11}
\citation{Fergus03}
\citation{Sivic05b}
\citation{Sivic08}
\citation{dai}
\citation{Frey_AffinityPropagation}
\citation{Frey_Dueck_2007}
\citation{Grauman06}
\citation{Tuytelaars_UnsupervisedSurvey}
\citation{gist}
\citation{Bosch:iccv07}
\citation{Ojala02}
\citation{deep:bmvc14}
\@writefile{toc}{\contentsline {section}{\numberline {3}Observations}{6}{section.3}}
\newlabel{sec:observations}{{3}{6}{Observations\relax }{section.3}{}}
\newlabel{sec:observation}{{3}{6}{Observations\relax }{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Observation 1}{6}{subsection.3.1}}
\newlabel{sec:mov1}{{3.1}{6}{Observation 1\relax }{subsection.3.1}{}}
\citation{lazebnik:cvpr06}
\citation{event-8}
\citation{lazebnik:cvpr06}
\citation{event-8}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The label co-occurrence probability $p(k)$: frequency of images having the same label with their $k_{th}$ neighbors. Results on six datasets are shown. The number of classes and the number of images of the datasets are shown as well. }}{7}{figure.2}}
\newlabel{fig:mov1}{{2}{7}{The label co-occurrence probability $p(k)$: frequency of images having the same label with their $k_{th}$ neighbors. Results on six datasets are shown. The number of classes and the number of images of the datasets are shown as well}{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Observation 2}{7}{subsection.3.2}}
\newlabel{sec:mov2}{{3.2}{7}{Observation 2\relax }{subsection.3.2}{}}
\citation{lazebnik:cvpr06}
\citation{deep:bmvc14}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Classification accuracy of ensemble learning on the the Scene-15 dataset\nobreakspace  {}\citep  {lazebnik:cvpr06} and the Event-8 dataset\nobreakspace  {}\citep  {event-8}, for varying training label noise $R$ and varying number of training trials $T$. Experiments on other datasets obtain the same trend. Ensemble learning is able to cancell out the deficiency of the training sets even it is very severe (e.g. $R=80\%$), given that the deficiency modes are different or `orthogonal' and the number of training sets are sufficiently large. The figure is best viewed in color.}}{8}{figure.3}}
\newlabel{fig:mov2}{{3}{8}{Classification accuracy of ensemble learning on the the Scene-15 dataset~\citep {lazebnik:cvpr06} and the Event-8 dataset~\citep {event-8}, for varying training label noise $R$ and varying number of training trials $T$. Experiments on other datasets obtain the same trend. Ensemble learning is able to cancell out the deficiency of the training sets even it is very severe (e.g. $R=80\%$), given that the deficiency modes are different or `orthogonal' and the number of training sets are sufficiently large. The figure is best viewed in color}{figure.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Our Approach}{9}{section.4}}
\newlabel{sec:approach}{{4}{9}{Our Approach\relax }{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Max-Min Sampling}{9}{subsection.4.1}}
\newlabel{sec:max-min}{{4.1}{9}{Max-Min Sampling\relax }{subsection.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Ensemble Projection}{9}{subsection.4.2}}
\citation{zhou:ensemble}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Max-Min Sampling in $t^{th}$ trial}}{10}{algocf.1}}
\newlabel{alg:max-min}{{1}{10}{Ensemble Projection\relax }{algocf.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Experiments}{10}{section.5}}
\newlabel{sec:experiments}{{5}{10}{Experiments\relax }{section.5}{}}
\citation{UIUC:Texture}
\citation{FeiFei2004}
\citation{stl-10}
\citation{lazebnik:cvpr06}
\citation{Indoor}
\citation{event-8}
\citation{building-25}
\citation{landuse21}
\citation{dai:eccv12b,dai:iccv13b}
\citation{gist}
\citation{Bosch:iccv07}
\citation{Ojala02}
\citation{caffe14,deep:bmvc14}
\citation{nips12:cnn,cnnfet14}
\citation{MatConvNet}
\citation{siftllc:cvpr10}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Ensemble Projection }}{11}{algocf.2}}
\newlabel{alg:ensemble:projection}{{2}{11}{Ensemble Projection\relax }{algocf.2}{}}
\citation{Zhu:Harmonic:03}
\citation{Belkin:semiframe:2006}
\citation{icml10:large:graph:ssl}
\citation{liblinear}
\citation{libsvm}
\citation{Belkin:semiframe:2006}
\citation{selftuning:04}
\citation{icml10:large:graph:ssl}
\citation{Zhu:Harmonic:03,Zhou:nips:04,icml10:large:graph:ssl,Fergus09,eccv10:ssl,ecml14:ssl}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Classification results of Ensemble Projection (EP) on the eight datasets, where three classifiers are used: $k$-NN, Logistic Regression, and SVMs with RBF kernels. All methods were tested with two feature inputs: the original deep feature and the learned feature by EP on top of it (indicated by ``+ EP"). }}{13}{figure.4}}
\newlabel{fig:results:baseline}{{4}{13}{Classification results of Ensemble Projection (EP) on the eight datasets, where three classifiers are used: $k$-NN, Logistic Regression, and SVMs with RBF kernels. All methods were tested with two feature inputs: the original deep feature and the learned feature by EP on top of it (indicated by ``+ EP")}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Semi-supervised Image Classification}{13}{subsection.5.1}}
\newlabel{sec:sic}{{5.1}{13}{Semi-supervised Image Classification\relax }{subsection.5.1}{}}
\citation{Belkin:semiframe:2006}
\citation{nips14:ssl}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Classification results of Ensemble Projection (EP) on the eight datasets, where three classifiers are used: $k$-NN, Logistic Regression, and SVMs with RBF kernels. All methods were tested with two feature inputs: the original deep feature and the learned feature by EP on top of it (indicated by ``+ EP"). }}{14}{figure.5}}
\newlabel{fig:results:ssl}{{5}{14}{Classification results of Ensemble Projection (EP) on the eight datasets, where three classifiers are used: $k$-NN, Logistic Regression, and SVMs with RBF kernels. All methods were tested with two feature inputs: the original deep feature and the learned feature by EP on top of it (indicated by ``+ EP")}{figure.5}{}}
\citation{ObjectAttribute:cvpr09,Transfer:CVPR:08}
\citation{deep:bmvc14}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces  Precision (\%) of image classification on the eight datasets, with $5$ labeled training examples per class. ``+ EP" indicate that classifiers working with our learned feature as input rather than the original CNN. The best performance is indicated in \textbf  {bold}, and the second best is \relax $\@@underline {\hbox {underlined}}\mathsurround \z@ $\relax . }}{15}{table.1}}
\newlabel{table:precision}{{1}{15}{Precision (\%) of image classification on the eight datasets, with $5$ labeled training examples per class. ``+ EP" indicate that classifiers working with our learned feature as input rather than the original CNN. The best performance is indicated in \textbf {bold}, and the second best is \underline {underlined}}{table.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Robustness to Parameters}{15}{subsubsection.5.1.1}}
\newlabel{sec:parameters}{{5.1.1}{15}{Robustness to Parameters\relax }{subsubsection.5.1.1}{}}
\citation{transformation:cvpr14}
\citation{cnnfet14}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces  MAP (\%) of semi-supervised classification on the eight datasets, with $5$ labeled training examples per class. ``LR + EP" indicate Logistic Regression with our learned feature as input. The other two classifiers use the original CNN feature as input. The best number is indicated in \textbf  {bold}. }}{16}{table.2}}
\newlabel{table:map}{{2}{16}{MAP (\%) of semi-supervised classification on the eight datasets, with $5$ labeled training examples per class. ``LR + EP" indicate Logistic Regression with our learned feature as input. The other two classifiers use the original CNN feature as input. The best number is indicated in \textbf {bold}}{table.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Performance of EP as a function its parameters $T$, $r$, $n$, and $m$, where LR is employed with $5$ labeled training images per class.}}{16}{figure.6}}
\newlabel{fig:mrnt}{{6}{16}{Performance of EP as a function its parameters $T$, $r$, $n$, and $m$, where LR is employed with $5$ labeled training images per class}{figure.6}{}}
\citation{deep:bmvc14}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Comparison of our learned feature to the CNN feature\nobreakspace  {}\cite  {deep:bmvc14}, with different LR models.}}{17}{figure.7}}
\newlabel{fig:classifiers}{{7}{17}{Comparison of our learned feature to the CNN feature~\cite {deep:bmvc14}, with different LR models}{figure.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Robustness to Classifier Models}{17}{subsubsection.5.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.3}Efficiency}{17}{subsubsection.5.1.3}}
\citation{neverhurt:icml11}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Self-taught classification results on dataset STL-10, where EP is learned from the unlabeled images. The classifiers were tested with deep features, and our learned feature from it (indicated by ``+ EP").}}{18}{figure.8}}
\newlabel{fig:stl}{{8}{18}{Self-taught classification results on dataset STL-10, where EP is learned from the unlabeled images. The classifiers were tested with deep features, and our learned feature from it (indicated by ``+ EP")}{figure.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Self-taught Image Classification}{18}{subsection.5.2}}
\newlabel{sec:self}{{5.2}{18}{Self-taught Image Classification\relax }{subsection.5.2}{}}
\citation{deep:bmvc14}
\citation{deep:bmvc14}
\citation{Sivic05b,Tuytelaars_UnsupervisedSurvey,dai,dai:eccv12b,fakton:eccv12}
\citation{parallel:sc}
\citation{vlfeat}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Purity (\%) of image clustering on the eight datasets, where the CNN feature \citep  {deep:bmvc14} and our learned feature from it (indicated by + EP) are used. The best results are indicated in \textbf  {bold}, and the second best is \relax $\@@underline {\hbox {underlined}}\mathsurround \z@ $\relax .}}{19}{table.3}}
\newlabel{table:clustering}{{3}{19}{Purity (\%) of image clustering on the eight datasets, where the CNN feature \citep {deep:bmvc14} and our learned feature from it (indicated by + EP) are used. The best results are indicated in \textbf {bold}, and the second best is \underline {underlined}}{table.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Image Clustering}{19}{subsection.5.3}}
\bibstyle{elsarticle-num}
\bibdata{egbib}
\bibcite{lazebnik:cvpr06}{{1}{}{{}}{{}}}
\bibcite{Indoor}{{2}{}{{}}{{}}}
\bibcite{siftllc:cvpr10}{{3}{}{{}}{{}}}
\bibcite{Sun_2010}{{4}{}{{}}{{}}}
\bibcite{Yang_2014_CVPR}{{5}{}{{}}{{}}}
\bibcite{nips12:cnn}{{6}{}{{}}{{}}}
\bibcite{game:purpose}{{7}{}{{}}{{}}}
\bibcite{labelme}{{8}{}{{}}{{}}}
\bibcite{stl-10}{{9}{}{{}}{{}}}
\bibcite{cnnfet14}{{10}{}{{}}{{}}}
\bibcite{feature:context}{{11}{}{{}}{{}}}
\bibcite{feature:LSTM}{{12}{}{{}}{{}}}
\bibcite{Fergus09}{{13}{}{{}}{{}}}
\bibcite{Guillaumin:cvpr:10}{{14}{}{{}}{{}}}
\bibcite{dai:iccv13b}{{15}{}{{}}{{}}}
\bibcite{JainK:cvpr09}{{16}{}{{}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{20}{section.6}}
\newlabel{sec:conclusion}{{6}{20}{Conclusion\relax }{section.6}{}}
\bibcite{cvpr09:multi:al}{{17}{}{{}}{{}}}
\bibcite{Transfer:CVPR:08}{{18}{}{{}}{{}}}
\bibcite{tl:survey}{{19}{}{{}}{{}}}
\bibcite{cvpr12:weak:video}{{20}{}{{}}{{}}}
\bibcite{metric:imitation}{{21}{}{{}}{{}}}
\bibcite{self-taught:icml07}{{22}{}{{}}{{}}}
\bibcite{Sivic05b}{{23}{}{{}}{{}}}
\bibcite{dai}{{24}{}{{}}{{}}}
\bibcite{SemiSVM}{{25}{}{{}}{{}}}
\bibcite{Joachims:1999}{{26}{}{{}}{{}}}
\bibcite{SemiBoost}{{27}{}{{}}{{}}}
\bibcite{SemiForest}{{28}{}{{}}{{}}}
\bibcite{gist}{{29}{}{{}}{{}}}
\bibcite{Ojala02}{{30}{}{{}}{{}}}
\bibcite{Bosch:iccv07}{{31}{}{{}}{{}}}
\bibcite{caffe14}{{32}{}{{}}{{}}}
\bibcite{rich:feature:cvpr14}{{33}{}{{}}{{}}}
\bibcite{deep:bmvc14}{{34}{}{{}}{{}}}
\bibcite{feature:video}{{35}{}{{}}{{}}}
\bibcite{Zhou:nips:04}{{36}{}{{}}{{}}}
\bibcite{deep:semi:embedding}{{37}{}{{}}{{}}}
\bibcite{Zhu:ISL:2009}{{38}{}{{}}{{}}}
\bibcite{nips14:ssl}{{39}{}{{}}{{}}}
\bibcite{Grauman06}{{40}{}{{}}{{}}}
\bibcite{Frey_AffinityPropagation}{{41}{}{{}}{{}}}
\bibcite{Rosch:1978}{{42}{}{{}}{{}}}
\bibcite{EnClasReview}{{43}{}{{}}{{}}}
\bibcite{dai:eccv12b}{{44}{}{{}}{{}}}
\bibcite{random:hashing}{{45}{}{{}}{{}}}
\bibcite{ObjectAttribute:cvpr09}{{46}{}{{}}{{}}}
\bibcite{eccv10:classemes}{{47}{}{{}}{{}}}
\bibcite{li:objectbank}{{48}{}{{}}{{}}}
\bibcite{augmented_attribute:eccv12}{{49}{}{{}}{{}}}
\bibcite{design_attribute:cvpr13}{{50}{}{{}}{{}}}
\bibcite{midlevel:transfer}{{51}{}{{}}{{}}}
\bibcite{cnn:transferable}{{52}{}{{}}{{}}}
\bibcite{mid-level:patches}{{53}{}{{}}{{}}}
\bibcite{learning:by:moving}{{54}{}{{}}{{}}}
\bibcite{book06:ssl}{{55}{}{{}}{{}}}
\bibcite{co-training:98}{{56}{}{{}}{{}}}
\bibcite{Semi:eccv12}{{57}{}{{}}{{}}}
\bibcite{Zhu:Harmonic:03}{{58}{}{{}}{{}}}
\bibcite{Belkin:semiframe:2006}{{59}{}{{}}{{}}}
\bibcite{ensemble:iccv11}{{60}{}{{}}{{}}}
\bibcite{Fergus03}{{61}{}{{}}{{}}}
\bibcite{Sivic08}{{62}{}{{}}{{}}}
\bibcite{Frey_Dueck_2007}{{63}{}{{}}{{}}}
\bibcite{Tuytelaars_UnsupervisedSurvey}{{64}{}{{}}{{}}}
\bibcite{event-8}{{65}{}{{}}{{}}}
\bibcite{zhou:ensemble}{{66}{}{{}}{{}}}
\bibcite{UIUC:Texture}{{67}{}{{}}{{}}}
\bibcite{FeiFei2004}{{68}{}{{}}{{}}}
\bibcite{building-25}{{69}{}{{}}{{}}}
\bibcite{landuse21}{{70}{}{{}}{{}}}
\bibcite{MatConvNet}{{71}{}{{}}{{}}}
\bibcite{icml10:large:graph:ssl}{{72}{}{{}}{{}}}
\bibcite{liblinear}{{73}{}{{}}{{}}}
\bibcite{libsvm}{{74}{}{{}}{{}}}
\bibcite{selftuning:04}{{75}{}{{}}{{}}}
\bibcite{eccv10:ssl}{{76}{}{{}}{{}}}
\bibcite{ecml14:ssl}{{77}{}{{}}{{}}}
\bibcite{transformation:cvpr14}{{78}{}{{}}{{}}}
\bibcite{neverhurt:icml11}{{79}{}{{}}{{}}}
\bibcite{fakton:eccv12}{{80}{}{{}}{{}}}
\bibcite{parallel:sc}{{81}{}{{}}{{}}}
\bibcite{vlfeat}{{82}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
