\chapter{Introduction}

A picture is worth a thousand of words, and often comes with a story that the photographer wanted to deliver. We probably still remember the moments when our grandparents were telling the stories behind the old picture at our home, be it about birthday parties, be it about holidays. While we as human generally enjoy browsing  personal picture collections, it has been getting prohibitively expensive to do so since the invention of digital cameras and the Internet. The inventions make it effortless ever to take pictures, store them, and share them with friends and families. Even more, camera sensors and images have been widely used in the society for many other purposes, such as for public security, for product control, for product description in E-commerce, to name a few. 
This leads to an outright explosion in the number of images and videos taken, which we will not ever have enough time and effort to read through.


%Taken YouTube as an example, it has 100 hours of videos (100 million frames) updated every minute. 
 
While the quantity and the quality of images taken everyday are steadily increasing, the collected data are of little use if they are unorganized, and cannot be transcribed into high-level information that suits and serves the application context. In computer vision, algorithms are designed specifically to tackle the fundamental problems of processing and understanding visual data, such as classifying images into different semantic classes, detecting  objects of particular classes, recognizing human actions, estimating human poses, and transcribing images/videos to natural languages. With algorithms from these sub-fields, images and videos can then be converted into semantic information so that the data can be used to its full potential.

%A plethora of methods have been developed to tackle each of the vision tasks, and great advances have been made in the past years. To the time being, computer vision can already recognize objects of thousands of categories, detecting objects in images in real time, and can already reconstruct 3D models at city- or world-scale.  Despite the great achievement,  the field still has to find means to keep up with the exploration of the massive amounts of data being captured on a daily basis. We believe this is mainly due to the lack of sufficient training annotations and the lack of computational resources. The thesis is dedicated to mitigate the problem.

The last decade has witnessed a great progress in high-level image processing and understanding, which comes as an outcome of three factors: 1) introduction of large-scale human annotations, such as ImageNet~\cite{} for image classification, Places~\cite{} for scene classification, MSCOCO for object detection~\cite{}, and VQA for visual question answering~\cite{}; 2) development of sophisticated, statistical learning approaches including support vector machines, boosting, random forests, and deep neural networks; and 3) accessibility to powerful computing infrastructures such as the GPUs and many software frameworks, such as CuNN, Caffe, Torch, and Theono. These advantages have helped the field achieved multiple milestones: computer vision is able to recognize objects of thousands of categories with super-human results~\cite{}, transcribe images/videos directly into natural languages, and answer basic questions about images~\cite{}. See Figure~\ref{fig:milestone} for results of current vision algorithms. 

Despite the great achievement, the field is still left behind by the exploration of visual data.  
It is evidenced by the facts that most of the benchmarks still only cover a small portion of the visual data that is available in the wild, and are collected under quite controlled scenarios. We speculate that this is mainly due to the fact that the speed of visual annotation cannot match that of visual data acquisition. Taking pictures, storing and sharing them are effortless nowadays. Annotating visual data in the form that machine can learn on, however, is tedious and very time-intensive. 
For example, 
%On one hand, an explosive amount of visual data is captured everyday and needs to be analyzed. 
%be it from surveillance cameras for security reasons, be it from industrial or mobile robot for controlling processes, be it the internet images uploaded by casual users due to social activities. 
YouTube has 100 hours of videos (100 million frames) updated every minute, while it required 19 man-years to label 1.2 million internet images. The annotations are done in the form of bounding boxes, rather than in more dedicated forms such as full segmentation masks. 

Another equally crucial factor is that visual data is very high-dimensional, which renders the corresponding algorithms computationally heavy at the training stage and at the test stage. For instance, training a state-of-the-art image classifier can take days or weeks even with modern GPUs, and computing the similarity among all images of a million-sized dataset can be prohibitively expensive. This heavy computation hinders the community from exploring new models.
All these numbers imply that there is a strong need to reduce the annotation cost and computational cost of current vision methods in order to better match the speed of data acquisition. 
The aim of this thesis is to provide a collection of methods which reduces the annotation cost and the computational cost of some popular vision algorithms. 


Every second, Millions of videos are generated and consumed every second. From the projected 859 petabytes of footage from surveillance cameras to the over two billion images and videos uploaded daily to social platforms, visual content is exploding. However, huge gaps exist between simply storing lots of data and the intelligent, insightful, and actionable understanding of this visual media.

%- See more at: https://news.developer.nvidia.com/upcoming-webinar-machine-learning-and-computer-vision-are-redefining-visual-search/#sthash.KKvElrdc.dpuf 


\subsection{Contributions}
The thesis is dedicated to mitigate the problem from multiple aspects. First, we elaborate three strategies to reduce the annotation costs in order to train vision algorithms: (1) developing smart annotation approaches for efficient, large-scale annotations; (2) learning better feature representation with unlabeled data; and (3) simulating training samples automatically. We develop algorithms for the three strategies and show in popular vision tasks that they are able to reduce the annotation costs considerably in training good vision algorithms.

Secondly, in addition to reducing annotation cost, we also examine how to reduce the computational cost associated with the training and testing of vision algorithms. The research in this vein leads to two contributions: (1) two efficient solvers for linear and kernel SVM+, significant speeding up the training process of SVM+ to explore privileged information; and (2) a method to allow computationally cheap features to imitate alternative features which perform better but are computationally more expensive. The imitation significantly improves the performance of the cheap features while retaining their efficiency.

Lastly, as images keep growing in size, vision algorithms need to be more intelligent and self-aware of its performance, be it the uncertainty of success, be it a better organization of the results, in order to be better integrated into real applications. To this aim, we develop two approaches: (1) Vision Forecasting to cheaply predict the success of vision algorithms for particular samples and to suggest the most-suitable method among multiple alternatives; and (2) Scale-Aware Image Segmentation to re-organize image segmentation hierarchies to better couple hierarchy depth and segmentation scale.
